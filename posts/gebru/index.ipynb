{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: Dr. Timnit Gebru\n",
    "author: Jack Greenburg\n",
    "date: '2023-04-018'\n",
    "description: \"Blog post #8: Dr. Timnit Gebru\"\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Dr. Timnit Gebru\n",
    "\n",
    "Dr. Timnit Gebru is a highly experienced and credentialed researcher who studies the social consequences of the advancement of artificial intelligence, and she will be delivering a talk on these issues to students at Middlebury College on April 24th. Dr. Gebru worked at Apple for many years before joining a lab under famed computer vision researcher Fei-Fei Li, at Stanford University. While there, her focus shifted more towards the sociological consequences of AI. After a few years at Stanford, she joined an AI ethics team at Google, ultimately leaving or being fired for writing a paper that some important people at Google very much did not like. Since then, she has continued to advocate for ethically focused AI. Her specific research focus appears to be in combating algorithmic bias. She was the second author on Joy Buolamwiniâ€™s famous paper that exposed how the best facial recognition software at the time performed significantly worse on Black women than White men."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computer vision in practice: who is benefiting and who is being harmed?\n",
    "\n",
    "Dr. Gebru opens her presentation by commenting on the extreme homogeneity of the machine learning community. She specifically comments on the underrepresentation of Black women, noting that often she was the only Black woman at conferences. She does highlight how the field of machine learning as a whole has improved (in part of course thanks to work by her and others), but she also points out that the computer vision subfield still lags behind.\n",
    "\n",
    "As evidence for the importance of diversity, Dr. Gebru highlights how different people could have vastly different perspectives on the same technologies. She provides many examples of applications of computer vision that could be discriminatory. She points out how there has been progress in people realizing the importance of diverse datasets, but she also argues that unbiased algorithms can still do damage. \n",
    "\n",
    "She talks about how, in search of diverse datasets, many people were included in datasets without their consent. She also talks about how people fail to consider how perfect classifiers can be used for dangerous purposes, so, even if a perfectly unbiased algorithm was possible, it would still be used to discriminate against marginalized groups. She also highlights how people naturally trust algorithms more than the accuracy of the model warrants. She advocates for the creation of a governmental oversight organization that would review AI applications for discrimination.\n",
    "\n",
    "TLDR: The lack of diversity within the field of computer vision coupled with the dogged pursuit of classification accuracy has led people to create (and employ) algorithms that can accidentally (or on purpose) reinforce systemic oppression.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proposed questions\n",
    "\n",
    "1. What are your thoughts on content suggestion algorithms on apps and sites such as Tik Tok, Instagram, Twitter, and Reddit.\n",
    "2. Do you think OpenAIs efforts to control the outputs of ChatGPT have been sufficient?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-0451",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f3d4450425a7130693d4d9c0be2f5039e43ea4835aeb8aae75f33fd35535b858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
